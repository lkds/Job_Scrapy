## 基于Scrapy的爬虫项目集合

利用Scrapy对国内的相关网站进行爬取，获取职业信息
### site
* [拉勾网](https://www.lagou.com/) 复活！
* ~~[智联招聘](https://www.zhilian.com/)~~
* ~~[BOSS直聘](https://www.zhipin.com/)~~
* [51Job](https://www.51job.com/)
* [58同城](https://cq.58.com/)
* [猎聘网](https://www.liepin.com/)
* [中聘网](https://www.cnzp.cn/)
* [大街网](https://www.dajie.com/) 臭鱼网站
* ~~[智通人才网](http://www.job5156.com/)~~丢弃

### 开发
* **安装python模块 pip install -r requirements.txt**
* 进入job目录，cd job
* 创建爬虫 scrapy genspider 网站名 域名
* 编写爬虫，仅填充能够爬取的字段

